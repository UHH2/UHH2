import re,os

def get_request_name(dataset_name):
    """Generate short string to use for request name from full dataset name

    Note that since this is used later on by e.g. multicrab status check,
    it should be invariant wrt time, commit hash, etc, otherwise it will not
    find the correct dir

    The short string generated by this function should however still contain as much information
    as needed so that people later on know which sample it is in CMS DAS (https://cmsweb.cern.ch/das)
    """

    is_real_data = dataset_name.split('/')[-1] == 'MINIAOD' # would be MINIAODSIM for MC
    # for real data, dataset names are usually not very long; thus, keep the full dataset name (except the obvious "MINIAOD" at the end) to prevent any confusion
    if is_real_data:
        modified_name = '_'.join(dataset_name.split('/')[1:-1])
        return modified_name

    # for the usually very long MC dataset names, do some more name modification ...

    # remove redundant substrings
    modified_name = dataset_name.split('/')[1].replace('Tune', '').replace('13TeV-', '').replace('13TeV_', '')

    campaign_etc = ''
    # Add MC campaign
    if "Summer16" in dataset_name:
        campaign_etc += "_Summer16"
    elif "Fall17" in dataset_name:
        campaign_etc += "_Fall17"
    elif "Autumn18" in dataset_name:
        campaign_etc += "_Autumn18"
    elif "Summer19UL17" in dataset_name:
        campaign_etc += "_Summer19UL17"
    elif "Summer19UL18" in dataset_name:
        campaign_etc += "_Summer19UL18"
    elif "Summer20UL16" in dataset_name:
        campaign_etc += "_Summer20UL16"
        if "APV" in dataset_name:
            campaign_etc += "APV"
    elif "Summer20UL17" in dataset_name:
        campaign_etc += "_Summer20UL17"
    elif "Summer20UL18" in dataset_name:
        campaign_etc += "_Summer20UL18"
    # Add 'ext1', 'ext2' etc.
    ext = re.search(r'ext[0-9]+', dataset_name.split('/')[-2])
    if ext:
        campaign_etc += '_'+ext.group(0)
    elif 'ext' in dataset_name:
        campaign_etc += '_ext'
    elif 'backup' in dataset_name:
        campaign_etc += '_backup'
    # Add sample version (last 'v*' before '/MINIAODSIM')
    version_number = dataset_name.split('/')[-2].split('-')[-1]
    if re.match(r'v[0-9]+', version_number):
        campaign_etc += '_'+version_number

    # request name can only be 100 characters maximum
    max_len = 100-len(campaign_etc)
    if len(modified_name) > max_len:
        modified_name = modified_name[:max_len]
    modified_name += campaign_etc

    return modified_name


def get_year(dataset):
    """Extract year string from DAS string.

    Note that this assumes that we will only run on UL samples, since it heavily relies on the naming scheme of those,
    and will raise exceptions if it can't find a UL-typical year
    """
    _,primary_ds_name,processed_ds_name,data_tier_name = tuple(dataset.split('/'))
    year_string='Run3'
    return year_string

def get_ntuplewriter(dataset, jetConstituents=False):
    """Generate the name of the ntuplewriter template that should be used, based on the DAS-string of the dataset"""

    ntuplewriter_name = 'ntuplewriter_'

    _,primary_ds_name,processed_ds_name,data_tier_name = tuple(dataset.split('/'))

    if(data_tier_name == 'MINIAODSIM'):
        ntuplewriter_name += 'mc_'
    elif(data_tier_name == 'MINIAOD'):
        ntuplewriter_name += 'data_'
    else:
        raise BaseException('Could not extract sample type (MC;DATA) from DAS string: %s'%dataset)

    ntuplewriter_name += get_year(dataset)

    if(jetConstituents):
        ntuplewriter_name += '_leadingjetConstits'

    ntuplewriter_name += '.py'
    return ntuplewriter_name

def get_outLFNDirBase(dataset, prefix = '/store/group/uhh/uhh2ntuples/Run3_124X_v1/'):
    """Build outLFNDirBase from dataset DAS string by adding year dependent subdir to prefix."""
    return os.path.join(prefix, get_year(dataset))
